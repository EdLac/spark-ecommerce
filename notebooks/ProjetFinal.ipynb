{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa561888",
   "metadata": {},
   "source": [
    "## 1) Initialisation & Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9cbe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.3\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c53e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, datediff, max as spark_max, sum as spark_sum, countDistinct, year, month, dayofweek, hour, quarter, count, round as spark_round, avg as spark_avg, when, desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b328a48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+---------+---------+--------------------+--------+----------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|     InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+----------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|01/12/2010 08:26|     2,55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|01/12/2010 08:26|     3,39|     17850|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|01/12/2010 08:26|     2,75|     17850|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|01/12/2010 08:26|     3,39|     17850|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|01/12/2010 08:26|     3,39|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+----------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Spark_Final_Project\").master(\"local[*]\").getOrCreate()\n",
    "\n",
    "df_raw = spark.read.option(\"Header\", True).option(\"inferSchema\", True).option(\"delimiter\", \";\").csv(\"../data/raw/Online_Retail_CSV.csv\")\n",
    "\n",
    "df_raw.printSchema()\n",
    "df_raw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3947e8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 541909 lignes.\n",
      "Il y a 8 colonnes.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Il y a {df_raw.count()} lignes.\")\n",
    "print(f\"Il y a {len(df_raw.columns)} colonnes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14428cc3",
   "metadata": {},
   "source": [
    "## 2) Exploration & Prétraitement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda05ad1",
   "metadata": {},
   "source": [
    "## A) Analyse Descriptive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58badfb0",
   "metadata": {},
   "source": [
    "Tout d'abord, regardons combien il y a de clients référencés dans cette base de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a762c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 4373 clients.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Il y a {df_raw.select('CustomerID').distinct().count()} clients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f781b5c2",
   "metadata": {},
   "source": [
    "Maintenant, regardons le nombre total de transactions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e480a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 25900 transactions uniques.\n"
     ]
    }
   ],
   "source": [
    "transaction_nb = df_raw.select('InvoiceNo').dropDuplicates().count()\n",
    "print(f\"Il y a {transaction_nb} transactions uniques.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08766b8d",
   "metadata": {},
   "source": [
    "Regardons de plus près la distribution de la variable Quantity :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c1bb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|          Quantity|\n",
      "+-------+------------------+\n",
      "|  count|            541909|\n",
      "|   mean|  9.55224954743324|\n",
      "| stddev|218.08115785023406|\n",
      "|    min|            -80995|\n",
      "|    max|             80995|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.select(\"Quantity\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919d8fbc",
   "metadata": {},
   "source": [
    "Nous observons qu’en moyenne, une ligne de commande contient environ 9 produits.  \n",
    "Cependant, l’écart-type est relativement élevé (218), ce qui indique une forte dispersion des valeurs et la présence d’outliers dans la variable Quantity.  \n",
    "En effet, certaines transactions présentent des quantités extrêmement faibles ou élevées, allant jusqu’à –80 995 et +80 995 unités.  \n",
    "Ces valeurs extrêmes contribuent fortement à l’augmentation de l’écart-type et sont susceptibles de correspondre à des retours de produits, des annulations de commandes ou des commandes en gros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add13571",
   "metadata": {},
   "source": [
    "Regardons egalement la distribution de la variable UnitPrice :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6794b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|         UnitPrice|\n",
      "+-------+------------------+\n",
      "|  count|            541909|\n",
      "|   mean|29.921163668665333|\n",
      "| stddev| 595.7455525989114|\n",
      "|    min|         -11062,06|\n",
      "|    max|             99,96|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.select(\"UnitPrice\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d5e197",
   "metadata": {},
   "source": [
    "Nous observons que le prix unitaire moyen d’un produit est d’environ 30 unités monétaires.  \n",
    "Toutefois, l’écart-type est particulièrement élevé (596), ce qui traduit une forte dispersion des valeurs et la présence d’outliers dans la variable UnitPrice.  \n",
    "En effet, certaines transactions présentent des valeurs négatives, pouvant atteindre –11 062, qui ne correspondent pas à des prix réels mais sont probablement liées à des remboursements, des annulations de commandes ou des écritures de correction comptable.  \n",
    "Ces valeurs extrêmes contribuent fortement à l’augmentation de l’écart-type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b4e01c",
   "metadata": {},
   "source": [
    "Maintenant, intéressons-nous au nombre de pays clients :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54c033e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 38 pays qui sont clients.\n"
     ]
    }
   ],
   "source": [
    "client_countries = df_raw.select(\"Country\").dropDuplicates().count()\n",
    "print(f\"Il y a {client_countries} pays qui sont clients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab40846",
   "metadata": {},
   "source": [
    "Regardons le nombre de commandes par pays : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09465bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|        Country|count|\n",
      "+---------------+-----+\n",
      "| United Kingdom|23494|\n",
      "|        Germany|  603|\n",
      "|         France|  461|\n",
      "|           EIRE|  360|\n",
      "|        Belgium|  119|\n",
      "|          Spain|  105|\n",
      "|    Netherlands|  101|\n",
      "|    Switzerland|   74|\n",
      "|       Portugal|   71|\n",
      "|      Australia|   69|\n",
      "|          Italy|   55|\n",
      "|        Finland|   48|\n",
      "|         Sweden|   46|\n",
      "|         Norway|   40|\n",
      "|Channel Islands|   33|\n",
      "|          Japan|   28|\n",
      "|         Poland|   24|\n",
      "|        Denmark|   21|\n",
      "|         Cyprus|   20|\n",
      "|        Austria|   19|\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.select(\"InvoiceNo\", \"Country\").dropDuplicates().groupby(\"Country\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f25b438",
   "metadata": {},
   "source": [
    "Nous observons que le jeu de données comprend des clients provenant de 38 pays différents, ce qui indique une base de clientèle internationale.  \n",
    "Toutefois, une très grande proportion des transactions est réalisée au Royaume-Uni, avec plus de 22 000 factures uniques, tandis que le deuxième pays, l’Allemagne, ne compte que 603 transactions.  \n",
    "Cela met en évidence un fort déséquilibre géographique, le Royaume-Uni dominant largement le jeu de données par rapport aux autres pays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8411aa73",
   "metadata": {},
   "source": [
    "Regardons maintenant le nombre total de commandes par clients, cela nous permettra de distinguer les clients habituels des clients ponctuels : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e685e6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|CustomerID|count|\n",
      "+----------+-----+\n",
      "|      NULL| 3710|\n",
      "|     14911|  248|\n",
      "|     12748|  224|\n",
      "|     17841|  169|\n",
      "|     14606|  128|\n",
      "|     15311|  118|\n",
      "|     13089|  118|\n",
      "|     12971|   89|\n",
      "|     14527|   86|\n",
      "|     13408|   81|\n",
      "|     14646|   77|\n",
      "|     16029|   76|\n",
      "|     16422|   75|\n",
      "|     14156|   66|\n",
      "|     13798|   63|\n",
      "|     18102|   62|\n",
      "|     13694|   60|\n",
      "|     15061|   55|\n",
      "|     17450|   55|\n",
      "|     16013|   54|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.select(\"CustomerID\", \"InvoiceNo\").dropDuplicates().groupBy(\"CustomerID\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84263f90",
   "metadata": {},
   "source": [
    "On remarque la présence d’un groupe CustomerID = NULL avec un nombre élevé de commandes. Cette observation suggère la présence de transactions sans identification client, ce qui motive l’analyse des valeurs manquantes présentée dans la section suivante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645d6419",
   "metadata": {},
   "source": [
    "## B) Vérifications de valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1738ff0",
   "metadata": {},
   "source": [
    "Avant toute analyse plus poussée, il est important de vérifier les valeurs nulles :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9401c441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|        0|        0|       1454|       0|          0|        0|    135080|      0|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum, when\n",
    "\n",
    "df_raw.select([sum(when(col(c).isNull(), 1 ).otherwise(0)).alias(c) for c in df_raw.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c084880a",
   "metadata": {},
   "source": [
    "Nous observons la présence de valeurs manquantes dans deux colonnes sur huit : Description et CustomerID.  \n",
    "La colonne Description contient un nombre relativement limité de valeurs manquantes (1 454), ce qui reste marginal au regard de la taille du jeu de données et n’impactera pas significativement l’analyse, d’autant plus que cette variable ne sera pas utilisée directement dans les modèles.  \n",
    "En revanche, la colonne CustomerID présente un nombre important de valeurs manquantes (135 080), ce qui constitue un enjeu majeur pour l’analyse, notamment pour la segmentation client. Ces lignes devront faire l’objet d’un traitement spécifique lors de la phase de nettoyage des données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b743346",
   "metadata": {},
   "source": [
    "Pour pallier au problème de valeurs manquantes mais egalement de prix et de quantité négatives, nous allons créer un nouveau dataset filtré sur ces trois conditions :  \n",
    "1 - Les valeurs de CustomerID doivent êtres Non Nulles  \n",
    "2 - Les valeurs de Quantity doivent êtres > 0  \n",
    "3 - Les valeurs unitaires des produits doivent êtres > 0  \n",
    "\n",
    "Nous créons donc ce dataset :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f093a305",
   "metadata": {},
   "source": [
    "# Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fc1c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleanV1 = (\n",
    "    df_raw\n",
    "    .filter(col(\"CustomerID\").isNotNull())\n",
    "    .filter(col(\"Quantity\") > 0)\n",
    "    .filter(col(\"UnitPrice\") > 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15911448",
   "metadata": {},
   "source": [
    "La colonne InvoiceDate est initialement stockée sous forme de chaîne de caractères.  \n",
    "Afin de permettre les calculs temporels nécessaires à l’analyse RFM, cette variable est convertie en format timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c175ab43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+-------------------+\n",
      "|        InvoiceDate|\n",
      "+-------------------+\n",
      "|2010-12-01 08:45:00|\n",
      "|2010-12-01 10:29:00|\n",
      "|2010-12-01 11:27:00|\n",
      "|2010-12-01 13:04:00|\n",
      "|2010-12-01 14:05:00|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp, col\n",
    "\n",
    "df_cleanV1 = df_cleanV1.withColumn(\"InvoiceDate\", to_timestamp(col(\"InvoiceDate\"), \"dd/MM/yyyy HH:mm\"))\n",
    "df_cleanV1.printSchema()\n",
    "df_cleanV1.select(\"InvoiceDate\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6761b7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "df_cleanV1 = df_cleanV1.withColumn(\"UnitPrice\", regexp_replace(col(\"UnitPrice\"), \",\", \".\" ).cast(\"double\"))\n",
    "\n",
    "df_cleanV1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c69d4",
   "metadata": {},
   "source": [
    "## Ajout de Colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644bd6c",
   "metadata": {},
   "source": [
    "Création Colonne TotalAmount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c3643b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Nouvelle colonne créée : TotalAmount = Quantity × UnitPrice\n",
      "\n",
      "--- Aperçu du dataset enrichi ---\n",
      "+---------+----------+--------+---------+-----------+-------------------+\n",
      "|InvoiceNo|CustomerID|Quantity|UnitPrice|TotalAmount|        InvoiceDate|\n",
      "+---------+----------+--------+---------+-----------+-------------------+\n",
      "|   536370|     12583|       3|     18.0|       54.0|2010-12-01 08:45:00|\n",
      "|   536392|     13705|       1|    165.0|      165.0|2010-12-01 10:29:00|\n",
      "|   536403|     12791|       1|     15.0|       15.0|2010-12-01 11:27:00|\n",
      "|   536527|     12662|       1|     18.0|       18.0|2010-12-01 13:04:00|\n",
      "|   536540|     14911|       1|     50.0|       50.0|2010-12-01 14:05:00|\n",
      "|   536779|     15823|       1|     15.0|       15.0|2010-12-02 15:08:00|\n",
      "|   536835|     13145|       1|    295.0|      295.0|2010-12-02 18:06:00|\n",
      "|   536840|     12738|       1|     18.0|       18.0|2010-12-02 18:27:00|\n",
      "|   536852|     12686|       1|     18.0|       18.0|2010-12-03 09:51:00|\n",
      "|   536858|     13520|       2|     40.0|       80.0|2010-12-03 10:36:00|\n",
      "+---------+----------+--------+---------+-----------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleanV1 = df_cleanV1.withColumn(\"TotalAmount\", col(\"Quantity\") * col(\"UnitPrice\"))\n",
    "\n",
    "print(\"✓ Nouvelle colonne créée : TotalAmount = Quantity × UnitPrice\")\n",
    "print(\"\\n--- Aperçu du dataset enrichi ---\")\n",
    "df_cleanV1.select(\"InvoiceNo\", \"CustomerID\", \"Quantity\", \"UnitPrice\", \"TotalAmount\", \"InvoiceDate\").show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fa9a1",
   "metadata": {},
   "source": [
    "Statistiques descriptives du dataset nettoyé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a3021d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Statistiques descriptives après nettoyage ---\n",
      "+-------+------------------+-----------------+------------------+\n",
      "|summary|          Quantity|        UnitPrice|       TotalAmount|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "|  count|              1712|             1712|              1712|\n",
      "|   mean| 5.136682242990654|35.89778037383178| 75.98072429906541|\n",
      "| stddev|18.870440432713025|76.74851762139058|105.17974474580936|\n",
      "|    min|                 1|              1.0|               1.0|\n",
      "|    max|               392|           2500.0|            2500.0|\n",
      "+-------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Statistiques descriptives après nettoyage ---\")\n",
    "df_cleanV1.select(\"Quantity\", \"UnitPrice\", \"TotalAmount\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9385ba75",
   "metadata": {},
   "source": [
    "## Colonnes temporelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaeb953",
   "metadata": {},
   "source": [
    "\n",
    "Pour identifier les patterns d'achat (clients qui achètent plutôt le weekend, en soirée, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "926052bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les composantes de la date\n",
    "df_cleanV1 = df_cleanV1.withColumn(\"Year\", year(\"InvoiceDate\"))\n",
    "df_cleanV1 = df_cleanV1.withColumn(\"Month\", month(\"InvoiceDate\"))\n",
    "df_cleanV1 = df_cleanV1.withColumn(\"Quarter\", quarter(\"InvoiceDate\"))  # Trimestre (1-4)\n",
    "df_cleanV1 = df_cleanV1.withColumn(\"DayOfWeek\", dayofweek(\"InvoiceDate\"))  # 1=Dimanche, 7=Samedi\n",
    "df_cleanV1 = df_cleanV1.withColumn(\"Hour\", hour(\"InvoiceDate\"))\n",
    "\n",
    "# Weekend ou semaine ?\n",
    "df_cleanV1 = df_cleanV1.withColumn(\n",
    "    \"IsWeekend\",\n",
    "    when((col(\"DayOfWeek\") == 1) | (col(\"DayOfWeek\") == 7), 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Période de la journée\n",
    "df_cleanV1 = df_cleanV1.withColumn(\n",
    "    \"TimeOfDay\",\n",
    "    when((col(\"Hour\") >= 6) & (col(\"Hour\") < 12), \"Morning\")\n",
    "    .when((col(\"Hour\") >= 12) & (col(\"Hour\") < 18), \"Afternoon\")\n",
    "    .when((col(\"Hour\") >= 18) & (col(\"Hour\") < 22), \"Evening\")\n",
    "    .otherwise(\"Night\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18ffb211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Par période de la journée\n",
      "+---------+----+-------+------+\n",
      "|TimeOfDay|  Nb| Revenu| Moyen|\n",
      "+---------+----+-------+------+\n",
      "|  Evening|  38| 5508.0|144.95|\n",
      "|  Morning| 658|51880.0| 78.84|\n",
      "|Afternoon|1016|72691.0| 71.55|\n",
      "+---------+----+-------+------+\n",
      "\n",
      "\n",
      "--- Weekend vs Semaine ---\n",
      "+-------+----+--------+-------+\n",
      "|   Type|  Nb|  Revenu|Moyenne|\n",
      "+-------+----+--------+-------+\n",
      "|Semaine|1578|122051.0|  77.35|\n",
      "|Weekend| 134|  8028.0|  59.91|\n",
      "+-------+----+--------+-------+\n",
      "\n",
      "\n",
      "--- Par Mois ---\n",
      "+-----+-------+-------+\n",
      "|Month| Revenu|Moyenne|\n",
      "+-----+-------+-------+\n",
      "|    1| 8943.0|  90.33|\n",
      "|    2| 5794.0|  70.66|\n",
      "|    3|11241.0|  92.14|\n",
      "|    4| 7338.0|  94.08|\n",
      "|    5| 8336.0|  72.49|\n",
      "|    6| 8766.0|  75.57|\n",
      "|    7| 6415.0|  59.95|\n",
      "|    8|12021.0|  86.48|\n",
      "|    9|13196.0|  72.11|\n",
      "|   10|12845.0|  65.87|\n",
      "|   11|22760.0|  76.38|\n",
      "|   12|12424.0|   69.8|\n",
      "+-----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyses colonnes temporelles\n",
    "print(\"\\n--- Par période de la journée\")\n",
    "df_cleanV1.groupBy(\"TimeOfDay\").agg(\n",
    "    count(\"*\").alias(\"Nb\"),\n",
    "    spark_round(spark_sum(\"TotalAmount\"), 0).alias(\"Revenu\"),\n",
    "    spark_round(spark_avg(\"TotalAmount\"), 2).alias(\"Moyen\")\n",
    ").show()\n",
    "\n",
    "print(\"\\n--- Weekend vs Semaine ---\")\n",
    "df_cleanV1.groupBy(when(col(\"IsWeekend\") == 1, \"Weekend\").otherwise(\"Semaine\").alias(\"Type\")).agg(\n",
    "    count(\"*\").alias(\"Nb\"),\n",
    "    spark_round(spark_sum(\"TotalAmount\"), 0).alias(\"Revenu\"),\n",
    "    spark_round(spark_avg(\"TotalAmount\"), 2).alias(\"Moyenne\")\n",
    ").show()\n",
    "\n",
    "print(\"\\n--- Par Mois ---\")\n",
    "df_cleanV1.groupBy(\"Month\").agg(\n",
    "    spark_round(spark_sum(\"TotalAmount\"), 0).alias(\"Revenu\"),\n",
    "    spark_round(spark_avg(\"TotalAmount\"), 2).alias(\"Moyenne\")\n",
    ").orderBy(\"Month\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049d672a",
   "metadata": {},
   "source": [
    "# 3) SEGMENTATION CLIENT (NON SUPERVISÉ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a08283e",
   "metadata": {},
   "source": [
    " --- 1. CRÉATION DES VARIABLES RFM ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eacc1f",
   "metadata": {},
   "source": [
    "Calculer la date de référence (date maximale dans le dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "046ef6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date de référence pour Recency : 2011-12-09 12:16:00\n"
     ]
    }
   ],
   "source": [
    "reference_date = df_cleanV1.select(spark_max(\"InvoiceDate\")).first()[0]\n",
    "print(f\"Date de référence pour Recency : {reference_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91007690",
   "metadata": {},
   "source": [
    "Calculer les variables RFM par client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "579011b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+--------+\n",
      "|CustomerID|Recency|Frequency|Monetary|\n",
      "+----------+-------+---------+--------+\n",
      "|     15727|    359|        1|   500.0|\n",
      "|     12471|      2|       21|  2400.0|\n",
      "|     16500|    330|        1|   165.0|\n",
      "|     12626|     23|        9|   666.0|\n",
      "|     12715|    106|        1|    80.0|\n",
      "|     12367|      4|        1|    18.0|\n",
      "|     17223|    368|        1|    35.0|\n",
      "|     16828|     93|        1|    15.0|\n",
      "|     13188|     11|        1|    15.0|\n",
      "|     17190|    207|        1|   195.0|\n",
      "+----------+-------+---------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------+------------------+------------------+-----------------+------------------+\n",
      "|summary|        CustomerID|           Recency|        Frequency|          Monetary|\n",
      "+-------+------------------+------------------+-----------------+------------------+\n",
      "|  count|               633|               633|              633|               633|\n",
      "|   mean|13995.001579778831|109.31911532385466|2.541864139020537|205.49605055292258|\n",
      "| stddev| 1745.467925818401|111.48999173667548|4.547419041303403| 526.8852231317848|\n",
      "|    min|             12348|                 0|                1|               1.0|\n",
      "|    max|             18283|               373|               85|           10496.0|\n",
      "+-------+------------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfm_data = df_cleanV1.groupBy(\"CustomerID\").agg(\n",
    "    datediff(lit(reference_date), spark_max(\"InvoiceDate\")).alias(\"Recency\"),\n",
    "    countDistinct(\"InvoiceNo\").alias(\"Frequency\"),  # compte les factures uniques\n",
    "    spark_sum(\"TotalAmount\").alias(\"Monetary\")     # total dépensé\n",
    ")\n",
    "\n",
    "# Affichage d'un aperçu\n",
    "rfm_data.show(10)\n",
    "rfm_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9edb24",
   "metadata": {},
   "source": [
    "## Verification du Dataframe RFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32b9a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Recency: integer (nullable = true)\n",
      " |-- Frequency: long (nullable = false)\n",
      " |-- Monetary: double (nullable = true)\n",
      "\n",
      "+----------+-------+---------+--------+\n",
      "|CustomerID|Recency|Frequency|Monetary|\n",
      "+----------+-------+---------+--------+\n",
      "|         0|      0|        0|       0|\n",
      "+----------+-------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfm_data.printSchema()\n",
    "\n",
    "# Vérification des valeurs nulles\n",
    "rfm_data.select([\n",
    "    spark_sum(when(col(c).isNull(), 1).otherwise(0)).alias(c) \n",
    "    for c in rfm_data.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf314733",
   "metadata": {},
   "source": [
    "## ASSEMBLAGE ET STANDARDISATION DES FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1f67c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1676011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1d833de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---------+--------+----------------------------------------------------------------+\n",
      "|CustomerID|Recency|Frequency|Monetary|features                                                        |\n",
      "+----------+-------+---------+--------+----------------------------------------------------------------+\n",
      "|15727     |359    |1        |500.0   |[2.2394914627481404,-0.33906357100941437,0.5589527595717295]    |\n",
      "|12471     |2      |21       |2400.0  |[-0.9625896786980496,4.0590356185184335,4.165051235263411]      |\n",
      "|16500     |330    |1        |165.0   |[1.97937842884915,-0.33906357100941437,-0.07685934008969834]    |\n",
      "|12626     |23     |9        |666.0   |[-0.7742319644953325,1.420176104801725,0.8740118895532133]      |\n",
      "|12715     |106    |1        |80.0    |[-0.029770522646498418,-0.33906357100941437,-0.2381847982127472]|\n",
      "+----------+-------+---------+--------+----------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assembler les features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Recency\", \"Frequency\", \"Monetary\"],\n",
    "    outputCol=\"features_raw\"\n",
    ")\n",
    "\n",
    "rfm_assembled = assembler.transform(rfm_data)\n",
    "\n",
    "# Standardiser\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features_raw\",\n",
    "    outputCol=\"features\",\n",
    "    withStd=True,\n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "scaler_model = scaler.fit(rfm_assembled)\n",
    "rfm_scaled = scaler_model.transform(rfm_assembled)\n",
    "\n",
    "rfm_scaled.select(\"CustomerID\", \"Recency\", \"Frequency\", \"Monetary\", \"features\").show(5, truncate=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
